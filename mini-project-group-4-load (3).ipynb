{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-05T01:39:26.219828Z","iopub.execute_input":"2024-11-05T01:39:26.220352Z","iopub.status.idle":"2024-11-05T01:39:27.282545Z","shell.execute_reply.started":"2024-11-05T01:39:26.220301Z","shell.execute_reply":"2024-11-05T01:39:27.281398Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/yelp-dataset/Dataset_User_Agreement.pdf\n/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\n","output_type":"stream"}]},{"cell_type":"code","source":"list_review = []\njson_review = pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\", chunksize = 50000, lines = True)\nfor chunk in json_review:\n    list_review.append(chunk)\ndf_review = pd.concat(list_review, ignore_index=True)\nprint(df_review.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_checkin = []\njson_checkin = pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\", chunksize = 50000, lines = True)\nfor chunk in json_checkin:\n    list_checkin.append(chunk)\ndf_checkin = pd.concat(list_checkin, ignore_index=True)\ndf_checkin = df_checkin.assign(date=df_checkin['date'].str.split(',')).explode('date')\ndf_checkin['date'] = pd.to_datetime(df_checkin['date'].str.strip())\nprint(df_checkin.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-04T23:04:49.313087Z","iopub.execute_input":"2024-11-04T23:04:49.313572Z","iopub.status.idle":"2024-11-04T23:05:04.220422Z","shell.execute_reply.started":"2024-11-04T23:04:49.313530Z","shell.execute_reply":"2024-11-04T23:05:04.219104Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"              business_id                date\n0  ---kPU91CF4Lq2-WlRu9Lw 2020-03-13 21:10:56\n0  ---kPU91CF4Lq2-WlRu9Lw 2020-06-02 22:18:06\n0  ---kPU91CF4Lq2-WlRu9Lw 2020-07-24 22:42:27\n0  ---kPU91CF4Lq2-WlRu9Lw 2020-10-24 21:36:13\n0  ---kPU91CF4Lq2-WlRu9Lw 2020-12-09 21:23:33\n","output_type":"stream"}]},{"cell_type":"code","source":"list_business = []\njson_business = pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\", chunksize = 50000, lines = True)\nfor chunk in json_business:\n    list_business.append(chunk)\ndf_business = pd.concat(list_business, ignore_index=True)\ndf_business = pd.json_normalize(df_business.to_dict(orient='records'))\nprint(df_business.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:20:54.441556Z","iopub.execute_input":"2024-11-04T20:20:54.442064Z","iopub.status.idle":"2024-11-04T20:21:07.038690Z","shell.execute_reply.started":"2024-11-04T20:20:54.442018Z","shell.execute_reply":"2024-11-04T20:21:07.037236Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"              business_id                      name  \\\n0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n\n                           address           city state postal_code  \\\n0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n2             5255 E Broadway Blvd         Tucson    AZ       85711   \n3                      935 Race St   Philadelphia    PA       19107   \n4                    101 Walnut St     Green Lane    PA       18054   \n\n    latitude   longitude  stars  review_count  ...  \\\n0  34.426679 -119.711197    5.0             7  ...   \n1  38.551126  -90.335695    3.0            15  ...   \n2  32.223236 -110.880452    3.5            22  ...   \n3  39.955505  -75.155564    4.0            80  ...   \n4  40.338183  -75.471659    4.5            13  ...   \n\n   attributes.AcceptsInsurance attributes.BestNights  attributes.BYOB  \\\n0                          NaN                   NaN              NaN   \n1                          NaN                   NaN              NaN   \n2                          NaN                   NaN              NaN   \n3                          NaN                   NaN              NaN   \n4                          NaN                   NaN              NaN   \n\n  attributes.Corkage attributes.BYOBCorkage attributes.HairSpecializesIn  \\\n0                NaN                    NaN                          NaN   \n1                NaN                    NaN                          NaN   \n2                NaN                    NaN                          NaN   \n3                NaN                    NaN                          NaN   \n4                NaN                    NaN                          NaN   \n\n  attributes.Open24Hours attributes.RestaurantsCounterService  \\\n0                    NaN                                  NaN   \n1                    NaN                                  NaN   \n2                    NaN                                  NaN   \n3                    NaN                                  NaN   \n4                    NaN                                  NaN   \n\n  attributes.AgesAllowed attributes.DietaryRestrictions  \n0                    NaN                            NaN  \n1                    NaN                            NaN  \n2                    NaN                            NaN  \n3                    NaN                            NaN  \n4                    NaN                            NaN  \n\n[5 rows x 60 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"list_tip = []\njson_tip = pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\", chunksize = 50000, lines = True)\nfor chunk in json_tip:\n    list_tip.append(chunk)\ndf_tip = pd.concat(list_tip, ignore_index=True)\nprint(df_tip.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_user = []\njson_user = pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\", chunksize = 50000, lines = True)\nfor chunk in json_user:\n    list_user.append(chunk)\ndf_user = pd.concat(list_user, ignore_index=True)\nprint(df_user.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sqlalchemy import create_engine\nimport sqlalchemy\n!pip install pyodbc\n!pip install sqlalchemy\n!pip install sqlalchemy pymssql pandas","metadata":{"execution":{"iopub.status.busy":"2024-11-05T01:39:41.382284Z","iopub.execute_input":"2024-11-05T01:39:41.382696Z","iopub.status.idle":"2024-11-05T01:40:17.435772Z","shell.execute_reply.started":"2024-11-05T01:39:41.382656Z","shell.execute_reply":"2024-11-05T01:40:17.434413Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pyodbc\n  Downloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\nDownloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyodbc\nSuccessfully installed pyodbc-5.2.0\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nCollecting pymssql\n  Downloading pymssql-2.3.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.1 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nDownloading pymssql-2.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymssql\nSuccessfully installed pymssql-2.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"username = 'sqladmin'\npassword = 'Group4123'\nserver = 'ruitaoj2-server.database.windows.net'\ndatabase = 'BADM_554_Group4'\n\nconnection_string = f\"mssql+pymssql://{username}:{password}@{server}:1433/{database}?charset=utf8\"\nengine = create_engine(connection_string)\n\ntry:\n    with engine.connect()as conn:\n        print(\"Connection to the Azure SOL Database instance is successful!\")\nexcept Exception as e:\n    print(\"Connection failed:\",e)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T01:41:34.422352Z","iopub.execute_input":"2024-11-05T01:41:34.423960Z","iopub.status.idle":"2024-11-05T01:41:34.952327Z","shell.execute_reply.started":"2024-11-05T01:41:34.423896Z","shell.execute_reply":"2024-11-05T01:41:34.951178Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Connection failed: (pymssql.exceptions.OperationalError) (40615, b\"Cannot open server 'ruitaoj2-server' requested by the login. Client with IP address '34.74.78.21' is not allowed to access the server.  To enable access, use the Azure Management Portal or run sp_set_firewall_rule on the master database to create a firewall rule for this IP address or address range.  It may take up to five minutes for this change to take effect.DB-Lib error message 20018, severity 14:\\nGeneral SQL Server error: Check messages from the SQL Server\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (ruitaoj2-server.database.windows.net)\\nDB-Lib error message 20002, severity 9:\\nAdaptive Server connection failed (ruitaoj2-server.database.windows.net)\\n\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_review.to_sql(name=\"table_name\", con=engine, if_exists='replace', index=False, chunksize=80000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_checkin.to_sql(name=\"checkin\", con=engine, if_exists='replace', index=False, chunksize=80000)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T23:35:36.233250Z","iopub.execute_input":"2024-11-04T23:35:36.233787Z","iopub.status.idle":"2024-11-05T00:40:08.149278Z","shell.execute_reply.started":"2024-11-04T23:35:36.233736Z","shell.execute_reply":"2024-11-05T00:40:08.147934Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"166875"},"metadata":{}}]},{"cell_type":"code","source":"df_business.to_sql(name=\"business\",  con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T20:21:20.636747Z","iopub.execute_input":"2024-11-04T20:21:20.637255Z","iopub.status.idle":"2024-11-04T20:41:05.659761Z","shell.execute_reply.started":"2024-11-04T20:21:20.637211Z","shell.execute_reply":"2024-11-04T20:41:05.658741Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}]},{"cell_type":"code","source":"df_tip.to_sql(name=\"tip\", con=engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_user.to_sql(name=\"user\", con=engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}